# End-to-End Data Engineering Pipeline for E-commerce Analytics

## 📌 Project Overview
This project demonstrates a production-grade data engineering workflow:
- Ingest raw e-commerce sales data from CSVs.
- Clean and transform large datasets using PySpark.
- Load into a PostgreSQL data warehouse.
- Build business intelligence dashboards in Tableau.

## 🚀 Tech Stack
- **Databricks / Apache Spark (PySpark)** for ETL
- **PostgreSQL** for Data Warehouse
- **Docker & Docker Compose** for containerization
- **Tableau** for BI Dashboards
- **Airflow** (optional) for orchestration

## 📂 Project Structure
data_raw/           # Raw data

data_processed/     # Cleaned data

scripts_ingestion/  # Ingestion scripts

scripts_transform/  # PySpark ETL jobs

sql/                # SQL schema & queries

docker/             # Docker setup

airflow/            # Airflow DAGs

tableau/            # Tableau dashboards

docs/               # ERD & architecture

## 🎯 Key Features
✅ End-to-end ETL pipeline  
✅ Scalable PySpark transformations  
✅ Star schema design in PostgreSQL  
✅ Tableau dashboards for sales insights  
✅ Dockerized for easy deployment

## ✅ Next Step for You
1️⃣ Create the GitHub repo data-engineering-ecommerce-analytics.

2️⃣ Push an empty structure (folders + README.md).